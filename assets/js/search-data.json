{
  
    
        "post0": {
            "title": "A Basic Neural Network: Differentiate Hand-Written Digits",
            "content": "Key Objectives: . Building a neural network that differentiates two hand-written digits 3 and 8. | Comparing the results of this Neural Network (NN) to that of a Logistic Regression (LR) model. | . Requirements: . &#39;Kudzu&#39; : A neural network library that was designed during our course by Univ.AI. | MNIST Database | . If MNIST is not installed, use the command !pip install mnist given below. It can be run both from the command line and Jupyter Notebook. . !pip install mnist . Collecting mnist Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB) Requirement already satisfied: numpy in /opt/hostedtoolcache/Python/3.6.14/x64/lib/python3.6/site-packages (from mnist) (1.19.5) Installing collected packages: mnist Successfully installed mnist-0.2.2 . Importing necessary libraries . %load_ext autoreload %autoreload 2 %matplotlib inline import matplotlib.pyplot as plt import numpy as np import pandas as pd . Preparing the Data . import mnist . train_images = mnist.train_images() train_labels = mnist.train_labels() . train_images.shape, train_labels.shape . ((60000, 28, 28), (60000,)) . test_images = mnist.test_images() test_labels = mnist.test_labels() . test_images.shape, test_labels.shape . ((10000, 28, 28), (10000,)) . image_index = 7776 # You may select anything up to 60,000 print(train_labels[image_index]) plt.imshow(train_images[image_index], cmap=&#39;Greys&#39;) . 2 . &lt;matplotlib.image.AxesImage at 0x7fe34d79e1d0&gt; . Filter data to get 3 and 8 out . train_filter = np.where((train_labels == 3 ) | (train_labels == 8)) test_filter = np.where((test_labels == 3) | (test_labels == 8)) X_train, y_train = train_images[train_filter], train_labels[train_filter] X_test, y_test = test_images[test_filter], test_labels[test_filter] . We normalize the pixel values in the 0 to 1 range . X_train = X_train/255. X_test = X_test/255. . Setup the labels as 1 (when the digit is 3) and 0 (when the digit is 8) . y_train = 1*(y_train==3) y_test = 1*(y_test==3) . X_train.shape, X_test.shape . ((11982, 28, 28), (1984, 28, 28)) . Reshape the input data to create a linear array . X_train = X_train.reshape(X_train.shape[0], -1) X_test = X_test.reshape(X_test.shape[0], -1) X_train.shape, X_test.shape . ((11982, 784), (1984, 784)) . Importing appropriate functions from &#39;Kudzu&#39; . from kudzu.layer import Sigmoid from kudzu.layer import Relu from kudzu.layer import Affine, Sigmoid from kudzu.model import Model from kudzu.train import Learner from kudzu.optim import GD from kudzu.data import Data, Dataloader, Sampler from kudzu.callbacks import AccCallback from kudzu.callbacks import ClfCallback from kudzu.loss import MSE . Let us create a Config class, to store important parameters. . This class essentially plays the role of a dictionary. . class Config: pass config = Config() config.lr = 0.001 config.num_epochs = 251 config.bs = 50 . Initializing data to the variables . data = Data(X_train, y_train.reshape(-1,1)) sampler = Sampler(data, config.bs, shuffle=True) dl = Dataloader(data, sampler) opt = GD(config.lr) loss = MSE() . training_xdata = X_train testing_xdata = X_test training_ydata = y_train.reshape(-1,1) testing_ydata = y_test.reshape(-1,1) . Running Models with the Training data . Details about the network layers: . A first affine layer has 784 inputs and does 100 affine transforms. These are followed by a Relu | A second affine layer has 100 inputs from the 100 activations of the past layer, and does 100 affine transforms. These are followed by a Relu | A third affine layer has 100 activations and does 2 affine transformations to create an embedding for visualization. There is no non-linearity here. | A final &quot;logistic regression&quot; which has an affine transform from 2 inputs to 1 output, which is squeezed through a sigmoid. | . Help taken from Anshuman&#39;s Notebook. . # layers for the Neural Network layers = [Affine(&quot;first&quot;, 784, 100), Relu(&quot;first&quot;), Affine(&quot;second&quot;, 100, 100), Relu(&quot;second&quot;), Affine(&quot;third&quot;, 100, 2), Affine(&quot;final&quot;, 2, 1), Sigmoid(&quot;final&quot;)] model_nn = Model(layers) # layers for the Logistic Regression layers_lr = [Affine(&quot;logits&quot;, 784, 1), Sigmoid(&quot;sigmoid&quot;)] model_lr = Model(layers_lr) . # suffix _nn stands for Neural Network. learner_nn = Learner(loss, model_nn, opt, config.num_epochs) acc_nn = ClfCallback(learner_nn, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_nn.set_callbacks([acc_nn]) . print(&quot;====== Neural Network ======&quot;) learner_nn.train_loop(dl) . ====== Neural Network ====== Epoch 0, Loss 0.2278 Training Accuracy: 0.7556, Testing Accuracy: 0.7424 Epoch 10, Loss 0.0845 Training Accuracy: 0.9109, Testing Accuracy: 0.9148 Epoch 20, Loss 0.0558 Training Accuracy: 0.9384, Testing Accuracy: 0.9466 Epoch 30, Loss 0.0442 Training Accuracy: 0.9503, Testing Accuracy: 0.9577 Epoch 40, Loss 0.038 Training Accuracy: 0.9573, Testing Accuracy: 0.9647 Epoch 50, Loss 0.0341 Training Accuracy: 0.9611, Testing Accuracy: 0.9682 Epoch 60, Loss 0.0314 Training Accuracy: 0.9638, Testing Accuracy: 0.9698 Epoch 70, Loss 0.0293 Training Accuracy: 0.9660, Testing Accuracy: 0.9708 Epoch 80, Loss 0.0277 Training Accuracy: 0.9685, Testing Accuracy: 0.9713 Epoch 90, Loss 0.0263 Training Accuracy: 0.9696, Testing Accuracy: 0.9713 Epoch 100, Loss 0.0251 Training Accuracy: 0.9705, Testing Accuracy: 0.9713 Epoch 110, Loss 0.0241 Training Accuracy: 0.9722, Testing Accuracy: 0.9718 Epoch 120, Loss 0.0232 Training Accuracy: 0.9735, Testing Accuracy: 0.9733 Epoch 130, Loss 0.0224 Training Accuracy: 0.9750, Testing Accuracy: 0.9733 Epoch 140, Loss 0.0216 Training Accuracy: 0.9756, Testing Accuracy: 0.9733 Epoch 150, Loss 0.021 Training Accuracy: 0.9768, Testing Accuracy: 0.9733 Epoch 160, Loss 0.0203 Training Accuracy: 0.9777, Testing Accuracy: 0.9733 Epoch 170, Loss 0.0198 Training Accuracy: 0.9785, Testing Accuracy: 0.9733 Epoch 180, Loss 0.0192 Training Accuracy: 0.9794, Testing Accuracy: 0.9738 Epoch 190, Loss 0.0187 Training Accuracy: 0.9804, Testing Accuracy: 0.9738 Epoch 200, Loss 0.0183 Training Accuracy: 0.9810, Testing Accuracy: 0.9738 Epoch 210, Loss 0.0178 Training Accuracy: 0.9813, Testing Accuracy: 0.9743 Epoch 220, Loss 0.0174 Training Accuracy: 0.9820, Testing Accuracy: 0.9748 Epoch 230, Loss 0.017 Training Accuracy: 0.9826, Testing Accuracy: 0.9753 Epoch 240, Loss 0.0166 Training Accuracy: 0.9831, Testing Accuracy: 0.9753 Epoch 250, Loss 0.0163 Training Accuracy: 0.9836, Testing Accuracy: 0.9753 . 0.05062484031787654 . Logistic Regression based Implementation. . learner_lr = Learner(loss, model_lr, opt, config.num_epochs) acc_lr = ClfCallback(learner_lr, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_lr.set_callbacks([acc_lr]) . print(&quot;====== Logistic Regression ======&quot;) learner_lr.train_loop(dl) . ====== Logistic Regression ====== Epoch 0, Loss 0.2511 Training Accuracy: 0.6647, Testing Accuracy: 0.6739 Epoch 10, Loss 0.1039 Training Accuracy: 0.9107, Testing Accuracy: 0.9249 Epoch 20, Loss 0.0796 Training Accuracy: 0.9286, Testing Accuracy: 0.9405 Epoch 30, Loss 0.0685 Training Accuracy: 0.9361, Testing Accuracy: 0.9531 Epoch 40, Loss 0.0618 Training Accuracy: 0.9406, Testing Accuracy: 0.9561 Epoch 50, Loss 0.0573 Training Accuracy: 0.9444, Testing Accuracy: 0.9597 Epoch 60, Loss 0.054 Training Accuracy: 0.9469, Testing Accuracy: 0.9607 Epoch 70, Loss 0.0514 Training Accuracy: 0.9496, Testing Accuracy: 0.9612 Epoch 80, Loss 0.0494 Training Accuracy: 0.9514, Testing Accuracy: 0.9622 Epoch 90, Loss 0.0477 Training Accuracy: 0.9528, Testing Accuracy: 0.9627 Epoch 100, Loss 0.0462 Training Accuracy: 0.9535, Testing Accuracy: 0.9637 Epoch 110, Loss 0.045 Training Accuracy: 0.9542, Testing Accuracy: 0.9637 Epoch 120, Loss 0.044 Training Accuracy: 0.9552, Testing Accuracy: 0.9647 Epoch 130, Loss 0.043 Training Accuracy: 0.9556, Testing Accuracy: 0.9667 Epoch 140, Loss 0.0422 Training Accuracy: 0.9565, Testing Accuracy: 0.9667 Epoch 150, Loss 0.0415 Training Accuracy: 0.9570, Testing Accuracy: 0.9672 Epoch 160, Loss 0.0408 Training Accuracy: 0.9577, Testing Accuracy: 0.9672 Epoch 170, Loss 0.0402 Training Accuracy: 0.9582, Testing Accuracy: 0.9672 Epoch 180, Loss 0.0396 Training Accuracy: 0.9585, Testing Accuracy: 0.9672 Epoch 190, Loss 0.0391 Training Accuracy: 0.9589, Testing Accuracy: 0.9672 Epoch 200, Loss 0.0386 Training Accuracy: 0.9591, Testing Accuracy: 0.9677 Epoch 210, Loss 0.0381 Training Accuracy: 0.9597, Testing Accuracy: 0.9682 Epoch 220, Loss 0.0377 Training Accuracy: 0.9601, Testing Accuracy: 0.9682 Epoch 230, Loss 0.0373 Training Accuracy: 0.9605, Testing Accuracy: 0.9693 Epoch 240, Loss 0.037 Training Accuracy: 0.9607, Testing Accuracy: 0.9688 Epoch 250, Loss 0.0366 Training Accuracy: 0.9609, Testing Accuracy: 0.9693 . 0.04126065747352803 . Comparing results of NN and LR . plt.figure(figsize=(15,10)) # Neural Network plots plt.plot(acc_nn.accuracies, &#39;r-&#39;, label = &quot;Training Accuracies - NN&quot;) plt.plot(acc_nn.test_accuracies, &#39;g-&#39;, label = &quot;Testing Accuracies - NN&quot;) # Logistic Regression plots plt.plot(acc_lr.accuracies, &#39;k-&#39;, label = &quot;Training Accuracies - LR&quot;) plt.plot(acc_lr.test_accuracies, &#39;b-&#39;, label = &quot;Testing Accuracies - LR&quot;) plt.ylim(0.8, 1) plt.legend() . &lt;matplotlib.legend.Legend at 0x7fe34537b128&gt; . From the plot, we can observe the following: . Neural Network achieves higher accuracy than the Logistic Regression model. | This apparently, is because of overfitting, i.e. NN captures more noise than data. | Testing accuracy of NN drops below the Training accuracy at higher epochs. This explains the over-fitting on training data. | Logistic Regression gives a reliable accuracy, without the above mentioned problem. | . Moving till the last but one layer (excluding it). . Plotting the outputs of this layer of the NN. . model_new = Model(layers[:-2]) . plot_testing = model_new(testing_xdata) . plt.figure(figsize=(8,7)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()); plt.title(&#39;Outputs&#39;) . Text(0.5, 1.0, &#39;Outputs&#39;) . Plotting probability contours . model_prob = Model(layers[-2:]) . # Adjust the x and y ranges according to the above generated plot. x_range = np.linspace(-4, 1, 100) y_range = np.linspace(-6, 6, 100) x_grid, y_grid = np.meshgrid(x_range, y_range) # x_grid and y_grig are of size 100 X 100 # converting x_grid and y_grid to continuous arrays x_grid_flat = np.ravel(x_grid) y_grid_flat = np.ravel(y_grid) # The last layer of the current model takes two columns as input. Hence transpose of np.vstack() is required. X = np.vstack((x_grid_flat, y_grid_flat)).T # x_grid and y_grid are of size 100 x 100 probability_contour = model_prob(X).reshape(100,100) . plt.figure(figsize=(10,9)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()) contours = plt.contour(x_grid,y_grid,probability_contour) plt.title(&#39;Probability Contours&#39;) plt.clabel(contours, inline = True ); .",
            "url": "https://akshithsriram.github.io/blog/2020/08/11/NeuralNetwork.html",
            "relUrl": "/2020/08/11/NeuralNetwork.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Covid-19 Dashboard: Auto-updated",
            "content": "Welcome! This version of the dashboard updates itself everyday with the latest information. . #collapse from datetime import datetime import pandas as pd import numpy as np # For making web-requests to the website import requests import json import matplotlib.pyplot as plt import matplotlib.dates as mdates import matplotlib as mpl %matplotlib inline from IPython.core.display import display,HTML latest_df = pd.read_csv(&quot;https://api.covid19india.org/csv/latest/state_wise_daily.csv&quot;) latest_df.head() df_1 = latest_df[(latest_df.Status == &quot;Confirmed&quot;)] df_1 = df_1.drop(columns = [&quot;Status&quot;]) df_2 = latest_df[(latest_df.Status == &quot;Deceased&quot;)] df_2 = df_2.drop(columns = [&quot;Status&quot;]) df_1[&quot;Date&quot;] = df_1[&quot;Date&quot;].astype(&#39;datetime64[ns]&#39;) update = latest_df.iloc[-1,0] cases = df_1.TT.sum() new = df_1.iloc[-1,2] deaths = df_2.TT.sum() df_new = df_2.iloc[-1,2] overview = &#39;&#39;&#39; &lt;!-- ####### HTML!! #########--&gt; &lt;h1 style=&quot;color: #5e9ca0; text-align: center;&quot;&gt;India&lt;/h1&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Last update: &lt;strong&gt;{update}&lt;/strong&gt;&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed cases:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{cases} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{new}&lt;/span&gt;)&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed deaths:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{deaths} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{df_new}&lt;/span&gt;)&lt;/p&gt; &#39;&#39;&#39; html = HTML(overview.format(update=update, cases=cases,new=new,deaths=deaths,df_new=df_new)) display(html) . . India . Last update: 31-Oct-21 . Confirmed cases: . 34284758 (+12907) . Confirmed deaths: . 458475 (+251) . #collapse current_time = datetime.now().time() # time object print(&quot;Last Updated: &quot;, current_time) . . Last Updated: 10:09:43.502721 . #collapse # For ten states n = 10 st = [&quot;TT&quot;, &quot;MH&quot;, &quot;TN&quot;, &quot;DL&quot;, &quot;KA&quot;, &quot;UP&quot;, &quot;BR&quot;, &quot;WB&quot;, &quot;TG&quot;, &quot;AP&quot;] state_name = [&quot;India&quot;, &quot;Maharashta&quot;, &quot;Tamil Nadu&quot;, &quot;Delhi&quot;, &quot;Karnataka&quot;, &quot;Uttar Pradesh&quot;, &quot;Bihar&quot;, &quot;West Bengal&quot;, &quot;Telangana&quot;, &quot;Andhra Pradesh&quot;] fig = plt.figure(figsize = (16,30)) gridspec = fig.add_gridspec(n, 3) size = df_1.shape[0] df_1.set_index(pd.Index(list(range(size))), inplace = True) # Displaying the latest 100 days info df_1 = df_1.loc[size-100:size] for i in range(n): ax = fig.add_subplot(gridspec[i, :]) ax.bar(df_1.Date,df_1[st[i]],alpha=0.3,color=&#39;#007acc&#39;) ax.plot(df_1.Date,df_1[st[i]] , marker=&quot;o&quot;, color=&#39;#007acc&#39;) ax.xaxis.set_major_locator(mdates.WeekdayLocator()) ax.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax.text(0.02, 0.9,state_name[i], transform = ax.transAxes, fontsize=25) ax.spines[&#39;right&#39;].set_visible(False) ax.spines[&#39;top&#39;].set_visible(False) . .",
            "url": "https://akshithsriram.github.io/blog/2020/08/11/CovidDashboard_auto_updated.html",
            "relUrl": "/2020/08/11/CovidDashboard_auto_updated.html",
            "date": " • Aug 11, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Covid-19 Dashboard",
            "content": "You are now in my dashboard! All the plots here are created using matplotlib (python). Use the &#39;Show Code&#39; option to take a look at the source code. . #collapse import pandas as pd import numpy as np import requests import json import matplotlib.pyplot as plt import matplotlib.dates as mdates import matplotlib as mpl from IPython.core.display import display,HTML %matplotlib inline dft_cases = pd.read_csv(&#39;data/SnapshotCases-28-July.csv&#39;) dft_deaths = pd.read_csv(&#39;data/SnapshotDeaths-28-July.csv&#39;) # cumulative number of cases &amp; deaths from 14-Jul-20 dft_cases[&quot;dt_today&quot;] = dft_cases[&quot;28-Jul-20&quot;] dft_cases[&quot;dt_yday&quot;] = dft_cases[&quot;27-Jul-20&quot;] dft_deaths[&quot;dt_today&quot;] = dft_deaths[&quot;28-Jul-20&quot;] dft_deaths[&quot;dt_yday&quot;] = dft_deaths[&quot;27-Jul-20&quot;] dfc_cases = dft_cases.groupby(&#39;states&#39;)[&quot;dt_today&quot;].sum() dfc_deaths = dft_deaths.groupby(&#39;states&#39;)[&quot;dt_today&quot;].sum() dfp_cases = dft_cases.groupby(&#39;states&#39;)[&quot;dt_yday&quot;].sum() dfp_deaths = dft_deaths.groupby(&#39;states&#39;)[&quot;dt_yday&quot;].sum() #Creating the new dataframe df_table df_dfc_cases = pd.DataFrame(dfc_cases).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_today&quot;: &quot;Cases&quot;}) df_dfp_cases = pd.DataFrame(dfp_cases).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_yday&quot;: &quot;PCases&quot;}) df_dfc_deaths = pd.DataFrame(dfc_deaths).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_today&quot;: &quot;Deaths&quot;}) df_dfp_deaths = pd.DataFrame(dfp_deaths).reset_index().rename(columns={&quot;states&quot;: &quot;states&quot;, &quot;dt_yday&quot;: &quot;PDeaths&quot;}) df_table = pd.merge(df_dfc_cases,df_dfp_cases, how=&#39;outer&#39;) df_table = pd.merge(df_table,df_dfc_deaths, how=&#39;outer&#39;) df_table = pd.merge(df_table,df_dfp_deaths, how=&#39;outer&#39;) for c in &#39;Cases, Deaths&#39;.split(&#39;, &#39;): df_table[f&#39;{c} (+)&#39;] = (df_table[c] - df_table[f&#39;P{c}&#39;]).clip(0) df_table[&#39;Fatality Rate&#39;] = (100* df_table[&#39;Deaths&#39;]/ df_table[&#39;Cases&#39;]).round(2) # Sorting the dataframe df_table.sort_values(by = [&#39;Cases&#39;,&#39;Deaths&#39;], ascending = [False, False], inplace = True) df_table.reset_index(drop=True, inplace = True) summary = {&quot;updated&quot;:&quot;28th July, 2020&quot;, &quot;since&quot;:&quot;27th July, 2020&quot;} for col in df_table.columns: if col not in [&quot;states&quot;, &quot;Fatality Rate&quot;]: summary[col]= df_table[col].sum() update = summary[&#39;updated&#39;] cases = summary[&#39;Cases&#39;] new = summary[&#39;Cases (+)&#39;] deaths = summary[&#39;Deaths&#39;] dnew = summary[&#39;Deaths (+)&#39;] # please un-comment the print statement to look at the summary dictionary. #print(summary) # HTML output. overview = &#39;&#39;&#39; &lt;!-- ####### HTML!! #########--&gt; &lt;h1 style=&quot;color: #5e9ca0; text-align: center;&quot;&gt;India&lt;/h1&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Last update: &lt;strong&gt;{update}&lt;/strong&gt;&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed cases:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{cases} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{new}&lt;/span&gt;)&lt;/p&gt; &lt;p style=&quot;text-align: center;&quot;&gt;Confirmed deaths:&lt;/p&gt; &lt;p style=&quot;text-align: center;font-size:24px;&quot;&gt;{deaths} (&lt;span style=&quot;color: #ff0000;&quot;&gt;+{dnew}&lt;/span&gt;)&lt;/p&gt; &#39;&#39;&#39; html = HTML(overview.format(update=update, cases=cases,new=new,deaths=deaths,dnew=dnew)) display(html) . . India . Last update: 28th July, 2020 . Confirmed cases: . 1514800 (+49001) . Confirmed deaths: . 34121 (+770) . #collapse dt_cols = list(dft_cases.columns[1:]) dft_ct_new_cases = dft_cases.groupby(&#39;states&#39;)[dt_cols].sum().diff(axis=1).fillna(0).astype(int) dft_ct_new_cases.sort_values(by = &#39;28-Jul-20&#39;, ascending = False,inplace = True) df = dft_ct_new_cases.copy() df.loc[&#39;Total&#39;] = df.sum() df.drop([&#39;dt_today&#39;, &#39;dt_yday&#39;], axis=1, inplace = True) n = 5 ef = df.loc[&#39;Total&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax = [] fig = plt.figure(figsize = (16,20)) gs = fig.add_gridspec(n+2, 3) # gs = fig.add_gridspec(2, 3) ax1 = fig.add_subplot(gs[0, :]) ef = df.loc[&#39;Total&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax1.bar(ef.date,ef.Total,alpha=0.3,color=&#39;#007acc&#39;) ax1.plot(ef.date,ef.Total , marker=&quot;o&quot;, color=&#39;#007acc&#39;) ax1.xaxis.set_major_locator(mdates.WeekdayLocator()) ax1.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax1.text(0.02, 0.5,&#39;India daily case count&#39;, transform = ax1.transAxes, fontsize=25); ax1.spines[&#39;right&#39;].set_visible(False) ax1.spines[&#39;top&#39;].set_visible(False) ax2 = fig.add_subplot(gs[1,0]) ef = df.loc[&#39;Maharashtra&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax2.bar(ef.date, ef.Maharashtra,color = &#39;#007acc&#39;,alpha=0.5) ax2.xaxis.set_major_locator(mdates.WeekdayLocator()) ax2.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax2.set_xticks(ax2.get_xticks()[::3]) maxyval = ef.Maharashtra.max() ax2.set_ylim([0,maxyval]) ax2.text(0.05, 0.5,&#39;Maharashtra&#39;, transform = ax2.transAxes, fontsize=20); ax2.spines[&#39;right&#39;].set_visible(False) ax2.spines[&#39;top&#39;].set_visible(False) ax3 = fig.add_subplot(gs[1,1]) ef = df.loc[&#39;Tamil Nadu&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax3.bar(ef.date, ef[&#39;Tamil Nadu&#39;],color = &#39;#007acc&#39;,alpha=0.5,) ax3.xaxis.set_major_locator(mdates.WeekdayLocator()) ax3.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax3.set_xticks(ax3.get_xticks()[::3]) ax3.text(0.05, 0.5,&#39;Tamil Nadu&#39;, transform = ax3.transAxes, fontsize=20); ax3.spines[&#39;right&#39;].set_visible(False) ax3.spines[&#39;top&#39;].set_visible(False) ax4 = fig.add_subplot(gs[1,2]) ef = df.loc[&#39;Delhi&#39;].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax4.bar(ef.date, ef.Delhi,color = &#39;#007acc&#39;,alpha=0.5) ax4.set_xticks([]) ax4.xaxis.set_major_locator(mdates.WeekdayLocator()) ax4.xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax4.set_xticks(ax4.get_xticks()[::3]) ax4.spines[&#39;right&#39;].set_visible(False) ax4.spines[&#39;top&#39;].set_visible(False) ax4.text(0.05, 0.5,&#39;Delhi&#39;, transform = ax4.transAxes, fontsize=20) for i in range(n): ax.append(fig.add_subplot(gs[i+2,:])) ef = df.iloc[i+3].rename_axis(&#39;date&#39;).reset_index() ef[&#39;date&#39;] = ef[&#39;date&#39;].astype(&#39;datetime64[ns]&#39;) ax[i].bar(ef.date,ef.iloc[:,-1],color = &#39;#007acc&#39;,alpha=0.3) ax[i].plot(ef.date,ef.iloc[:,-1],marker=&#39;o&#39;,color=&#39;#007acc&#39;) ax[i].text(0.02,0.5,f&#39;{ef.columns.values[-1]}&#39;,transform = ax[i].transAxes, fontsize = 20); ax[i].xaxis.set_major_locator(mdates.WeekdayLocator()) ax[i].xaxis.set_major_formatter(mdates.DateFormatter(&#39;%b %d&#39;)) ax[i].set_ylim([0,7000]) ax[i].spines[&#39;right&#39;].set_visible(False) ax[i].spines[&#39;top&#39;].set_visible(False) plt.tight_layout() . . #collapse print(df_table.to_string(index=False)) . . states Cases PCases Deaths PDeaths Cases (+) Deaths (+) Fatality Rate Maharashtra 391440 383723 14164 13882 7717 282 3.62 Tamil Nadu 227688 220716 3659 3571 6972 88 1.61 Delhi 132275 131219 3881 3853 1056 28 2.93 Andhra Pradesh 110297 102349 1148 1090 7948 58 1.04 Karnataka 107001 101465 2064 1962 5536 102 1.93 Uttar Pradesh 73951 70493 1497 1456 3458 41 2.02 West Bengal 62964 60830 1449 1411 2134 38 2.30 Gujarat 57982 56874 2372 2348 1108 24 4.09 Telangana 57142 55532 480 471 1610 9 0.84 Bihar 43591 41111 269 255 2480 14 0.62 Rajasthan 38636 37564 644 633 1072 11 1.67 Assam 34846 33475 92 90 1371 2 0.26 Haryana 32876 32127 406 397 749 9 1.23 Madhya Pradesh 29217 28589 831 821 628 10 2.84 Orissa 28107 26892 189 181 1215 8 0.67 Kerala 20895 19728 68 64 1167 4 0.33 Jammu and Kashmir 18879 18390 333 321 489 12 1.76 Punjab 14378 13769 336 318 609 18 2.34 Jharkhand 9563 8803 94 90 760 4 0.98 Goa 5287 5119 36 36 168 0 0.68 Tripura 4287 4066 21 17 221 4 0.49 Pondicherry 3013 2874 47 43 139 4 1.56 Himachal Pradesh 2330 2270 13 13 60 0 0.56 Manipur 2317 2286 0 0 31 0 0.00 Nagaland 1460 1385 4 5 75 0 0.27 Arunachal Pradesh 1330 1239 3 3 91 0 0.23 Chandigarh 934 910 14 14 24 0 1.50 Meghalaya 779 738 5 5 41 0 0.64 Sikkim 592 568 1 1 24 0 0.17 Mizoram 384 361 0 0 23 0 0.00 Andaman and Nicobar Islands 359 334 1 1 25 0 0.28 Daman and Diu 0 0 0 0 0 0 NaN Lakshadweep 0 0 0 0 0 0 NaN .",
            "url": "https://akshithsriram.github.io/blog/2020/07/28/CovidDashboard.html",
            "relUrl": "/2020/07/28/CovidDashboard.html",
            "date": " • Jul 28, 2020"
        }
        
    
  

  
  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://akshithsriram.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}